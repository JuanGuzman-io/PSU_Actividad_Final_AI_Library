# Librer√≠a de Detecci√≥n de Fraude - PSU Actividad Final

Sistema de detecci√≥n de fraude en transacciones financieras desarrollado como parte del proyecto final de Fundamentos de IA para Ingenieros de Software.

## üë• Autores
- **Delgado Guzm√°n, Juan David**
- **Fonseca Bello, Diego Fernando**
- **J√°come Jami, Daniela Estefan√≠a**
- **Parra S√∫a, Yohn Eduin**
- **Poveda Melo, Ingrid Carolina**

## üìã Descripci√≥n

Esta librer√≠a proporciona una interfaz de alto nivel para entrenar, guardar, cargar y usar modelos de inteligencia artificial especializados en la detecci√≥n de fraude en transacciones financieras.

## üéØ Caracter√≠sticas Principales

- ‚úÖ **Entrenamiento autom√°tico** con Random Forest y Regresi√≥n Log√≠stica
- ‚úÖ **Balanceo de clases** autom√°tico con SMOTE
- ‚úÖ **Validaci√≥n cruzada** estratificada
- ‚úÖ **Persistencia de modelos** con joblib
- ‚úÖ **M√©tricas especializadas** para detecci√≥n de fraude
- ‚úÖ **Visualizaciones** autom√°ticas de resultados
- ‚úÖ **Predicciones en tiempo real**

## üöÄ Instalaci√≥n

1. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

2. **Generar datos de prueba (opcional):**
```bash
python data_generator.py
```

## üíª Uso B√°sico

### Ejemplo Completo

```python
from AIlibrary import FraudDetectionLibrary
import pandas as pd

# 1. Cargar datos
df = pd.read_csv('data.csv')

# 2. Crear instancia de la librer√≠a
detector = FraudDetectionLibrary()

# 3. Entrenar modelo
params = {
    'algorithm': 'random_forest',
    'n_estimators': 100,
    'use_smote': True
}
results = detector.train_model(df, train_params=params)

# 4. Guardar modelo
detector.save_model('mi_modelo')

# 5. Cargar modelo (en otra sesi√≥n)
nuevo_detector = FraudDetectionLibrary()
nuevo_detector.load_model('mi_modelo')

# 6. Hacer predicciones
predicciones = nuevo_detector.test_model(nuevos_datos)
```

### Funciones Principales

#### `train_model(data, train_params=None)`
Entrena un modelo de clasificaci√≥n para detecci√≥n de fraude.

**Par√°metros:**
- `data`: DataFrame con datos preprocesados
- `train_params`: Diccionario con par√°metros de entrenamiento

**Retorna:** Diccionario con matriz de confusi√≥n y m√©tricas

#### `save_model(model_name, save_path='./models/')`
Guarda el modelo entrenado y sus componentes.

**Par√°metros:**
- `model_name`: Nombre para el modelo
- `save_path`: Directorio donde guardar

**Retorna:** Ruta donde se guard√≥ el modelo

#### `load_model(model_name, load_path='./models/')`
Carga un modelo previamente entrenado.

#### `test_model(data)`
Realiza predicciones sobre nuevos datos.

#### `data_clean(data_path, outlier_limit=2700, columns_to_remove=None)`
Limpia y preprocesa datos crudos de transacciones.

**Par√°metros:**
- `data_path`: Ruta al archivo CSV crudo
- `outlier_limit`: L√≠mite para filtrar outliers por monto
- `columns_to_remove`: Columnas a eliminar

**Retorna:** DataFrame limpio listo para entrenamiento

**Funcionalidades:**
- Filtrado de outliers por monto
- Procesamiento de fechas y caracter√≠sticas temporales
- C√°lculo de edad del titular
- C√°lculo de distancia geogr√°fica entre cliente y comercio
- Codificaci√≥n de variables categ√≥ricas
- Manejo de valores nulos

### üåä Pipeline Completo con data_clean()

```python
from AIlibrary import data_clean, FraudDetectionLibrary

# 1. Limpiar datos crudos
cleaned_df = data_clean('credit_card_transactions.csv')

# 2. Entrenar modelo
detector = FraudDetectionLibrary()
results = detector.train_model(cleaned_df)

# 3. Guardar modelo
detector.save_model('mi_modelo')

# 4. Usar modelo
predicciones = detector.test_model(nuevos_datos)
```

## üìä Ejecutar Demo

### üöÄ **AppCompletePipeline.py** - Pipeline Completo (RECOMENDADO)
**Uso:** Demostraci√≥n del pipeline completo desde datos crudos hasta predicciones

```bash
python AppCompletePipeline.py
```

**Caracter√≠sticas:**
- ‚úÖ **Pipeline completo**: datos crudos ‚Üí limpieza ‚Üí entrenamiento ‚Üí predicciones
- ‚úÖ **Incluye `data_clean()`**: procesa datos sin preprocesar
- ‚úÖ **Realistic workflow**: simula un caso de uso real
- ‚úÖ **R√°pida ejecuci√≥n**: sin visualizaciones pesadas
- ‚úÖ **Ideal para entrega**: muestra todas las funcionalidades requeridas

### üé® **App.py** - Demo con Visualizaciones
**Uso:** Demostraci√≥n completa con gr√°ficos y an√°lisis visual

```bash
python App.py
```

**Caracter√≠sticas:**
- ‚úÖ **Visualizaciones**: gr√°ficos de m√©tricas y an√°lisis
- ‚úÖ **An√°lisis detallado**: casos de alto riesgo con estad√≠sticas
- ‚úÖ **Demo interactiva**: simulaci√≥n de predicciones en tiempo real
- ‚úÖ **Datos sint√©ticos**: genera datos si no encuentra el archivo original
- ‚úÖ **Ideal para presentaciones**: m√°s visual y completo

### ‚ö° **Alternativa: data_cleaning.py**
**Uso:** Si prefieres usar la funci√≥n de limpieza por separado

```bash
python data_cleaning.py
```

**Caracter√≠sticas:**
- ‚úÖ **Funci√≥n standalone**: limpieza independiente
- ‚úÖ **Compatible**: con el trabajo de tu compa√±ero
- ‚úÖ **Modular**: usar solo la parte que necesites

### üìã **¬øCu√°l ejecutar?**

| Prop√≥sito | Archivo Recomendado |
|-----------|--------------------|
| **Entrega del proyecto** | `AppCompletePipeline.py` ‚úÖ |
| **Presentaci√≥n visual** | `App.py` üé® |
| **Solo limpieza de datos** | `data_cleaning.py` üßΩ |

El demo ejecutar√° autom√°ticamente:
1. Carga de datos
2. Entrenamiento del modelo
3. Evaluaci√≥n con m√©tricas
4. Guardado y carga del modelo
5. Predicciones en tiempo real
6. Visualizaciones

## üîß Par√°metros de Entrenamiento

```python
train_params = {
    'algorithm': 'random_forest',        # 'random_forest' o 'logistic_regression'
    'n_estimators': 100,                 # N√∫mero de √°rboles (Random Forest)
    'max_depth': 10,                     # Profundidad m√°xima
    'test_size': 0.2,                    # Proporci√≥n para test
    'use_smote': True,                   # Balanceo con SMOTE
    'cv_folds': 5,                       # Folds para validaci√≥n cruzada
    'random_state': 42                   # Semilla aleatoria
}
```

## üìà M√©tricas Incluidas

- **Matriz de Confusi√≥n**
- **Precisi√≥n, Recall, F1-Score**
- **AUC-ROC**
- **Validaci√≥n Cruzada**
- **Importancia de Caracter√≠sticas**

## üìÅ Estructura del Proyecto

```
PSU_Actividad_Final/
‚îú‚îÄ‚îÄ üé® App.py                    # Demo con visualizaciones y gr√°ficos
‚îú‚îÄ‚îÄ üöÄ AppCompletePipeline.py     # Pipeline completo (RECOMENDADO)
‚îú‚îÄ‚îÄ üß† AIlibrary.py              # Librer√≠a principal de detecci√≥n de fraude
‚îú‚îÄ‚îÄ üßΩ data_cleaning.py          # Funci√≥n de limpieza separada
‚îú‚îÄ‚îÄ üìÑ README.md                 # Documentaci√≥n (este archivo)
‚îú‚îÄ‚îÄ üìé requirements.txt          # Dependencias del proyecto
‚îú‚îÄ‚îÄ üìã credit_card_transactions.csv # Dataset crudo
‚îî‚îÄ‚îÄ üìÅ models/                   # Modelos entrenados guardados
    ‚îú‚îÄ‚îÄ fraud_detector_v1_model.joblib
    ‚îú‚îÄ‚îÄ fraud_detector_v1_scaler.joblib
    ‚îî‚îÄ‚îÄ fraud_detector_v1_metadata.joblib
```

### üîë **Archivos Principales:**

- **`AppCompletePipeline.py`** ‚úÖ **Para entrega**: Pipeline completo con `data_clean()`
- **`App.py`** üé® **Para presentar**: Demo visual con gr√°ficos 
- **`AIlibrary.py`** üß† **Core**: Librer√≠a principal con todas las funciones
- **`data_cleaning.py`** üßΩ **Utilidad**: Funci√≥n de limpieza separada

## üéØ Transferir Datos Reales

Para usar los datos procesados desde Colab:

1. En Colab, despu√©s de ejecutar `data_clean()`:
```python
# Guardar datos limpios
cleaned_df.to_csv('credit_card_clean.csv', index=False)

# Descargar archivo
from google.colab import files
files.download('credit_card_clean.csv')
```

2. Colocar el archivo como `data.csv` en este directorio

## üìä Resultados Esperados

La librer√≠a est√° optimizada para datasets de fraude y deber√≠a lograr:
- **F1-Score**: > 0.85
- **Recall**: > 0.80 (importante para detectar fraudes)
- **Precisi√≥n**: > 0.85
- **AUC-ROC**: > 0.90

## üîç Soluci√≥n de Problemas

### Error: "Columna 'is_fraud' no encontrada"
Aseg√∫rate de que tu dataset tenga una columna llamada `is_fraud` con valores 0/1.

### Error: "Faltan caracter√≠sticas"
Verifica que los datos de predicci√≥n tengan las mismas columnas que los datos de entrenamiento.

### Error: "Modelo no encontrado"
Aseg√∫rate de entrenar y guardar el modelo antes de intentar cargarlo.

---
**Universidad Internacional de La Rioja (UNIR)**  
Programa Superior Universitario en Inteligencia Artificial para Desarrollo de Software y DevOps
